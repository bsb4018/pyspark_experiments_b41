{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyRFaPks98K4",
        "outputId": "be22b468-089e-4d6e-b131-df0cb1fb093d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=df18a39aaa567decafc8725a5fbab94dc51fe2241e7c52ff3ac25cc0adcf880e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"drive/MyDrive/adv_analytics/all_blocks.csv\""
      ],
      "metadata": {
        "id": "zMIjYwaM-Cgj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "Xf-nOZGaAdxS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "NxerqHIXAsIE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Adv_Analytics').getOrCreate()"
      ],
      "metadata": {
        "id": "l4yW4Od-AyRy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev = spark.read.csv(filepath)"
      ],
      "metadata": {
        "id": "biQcSN0j-CjI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbWK0qNP-Crq",
        "outputId": "9ac69001-74b1-41fc-b613-0d4881d9843a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prev.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBWKTlrO-CuQ",
        "outputId": "707ff7af-098d-4e8b-be26-e25d9abce58d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "|  _c0|  _c1|              _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
            "|37291|53113|0.833333333333333|           ?|         1.0|           ?|      1|     1|     1|     1|      0|    True|\n",
            "|39086|47614|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    True|\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing Schema Inference and Missing Values Set to Null -> the column names are set correctly and the ? strings have been replaced by null values"
      ],
      "metadata": {
        "id": "RYKXCzHNGUKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed = spark.read.option(\"header\", \"true\").option(\"nullValue\", \"?\").\\\n",
        "option(\"inferSchema\", \"true\").csv(filepath)"
      ],
      "metadata": {
        "id": "e3yA_iQ4-CwZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbFv04QYBXcK",
        "outputId": "4e85f097-9bb4-42f9-d316-2ea99f72dfc6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id_1: integer (nullable = true)\n",
            " |-- id_2: integer (nullable = true)\n",
            " |-- cmp_fname_c1: double (nullable = true)\n",
            " |-- cmp_fname_c2: double (nullable = true)\n",
            " |-- cmp_lname_c1: double (nullable = true)\n",
            " |-- cmp_lname_c2: double (nullable = true)\n",
            " |-- cmp_sex: integer (nullable = true)\n",
            " |-- cmp_bd: integer (nullable = true)\n",
            " |-- cmp_bm: integer (nullable = true)\n",
            " |-- cmp_by: integer (nullable = true)\n",
            " |-- cmp_plz: integer (nullable = true)\n",
            " |-- is_match: boolean (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Schema Inference does two passes -> one pass to figure out the type of each column, and a second pass to do the actual parsing.\n",
        "# If you know the schema that you want to use for a file ahead of time, you can create an instance of the pyspark.sql.types.StructType \n",
        "# class and pass it to the Reader # API via the schema function. This can have a significant performance benefit when the dataset is \n",
        "# very large, since Spark will not need to perform an extra pass over the data to figure out the data type of each column."
      ],
      "metadata": {
        "id": "hY0S7r9eBXe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "bDjoHYBrBXha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#schema = StructType([StructField(\"id_1\", IntegerType(), False),\n",
        "#StructField(\"id_2\", StringType(), False),\n",
        "#StructField(\"cmp_fname_c1\", DoubleType(), False)])"
      ],
      "metadata": {
        "id": "EkWzQ16VBXjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parsed2 = spark.read.schema(schema).csv(filepath)"
      ],
      "metadata": {
        "id": "ou9Yd743BXmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXHpuAd4BXq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrames have a number of methods that enable us to read data from the cluster into the PySpark REPL on our client machine."
      ],
      "metadata": {
        "id": "JG6r_MO-BXte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed.first()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXn5OjybBXvz",
        "outputId": "84a9e5c4-1b59-470d-a3ed-df7e0307ed5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(id_1=37291, id_2=53113, cmp_fname_c1=0.833333333333333, cmp_fname_c2=None, cmp_lname_c1=1.0, cmp_lname_c2=None, cmp_sex=1, cmp_bd=1, cmp_bm=1, cmp_by=1, cmp_plz=0, is_match=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we know the dataset is small -> only then we can use the toPandas or collect method to return all the contents of a DataFrame to the client as an array. "
      ],
      "metadata": {
        "id": "ce2V8zxRBXyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing Data with the DataFrame API"
      ],
      "metadata": {
        "id": "qbuhYSs8BX07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting an idea of the number of records\n",
        "parsed.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37PJbMIDBX3U",
        "outputId": "dbc3cc0f-a322-4a48-9e66-8d368c30a007"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5749132"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Whenever we ask another question -> do another computation, Spark will do these same operations, again and again, even if we have filtered the \n",
        "# Analyzing Data with the DataFrame API data down to a small number of records or are working with an aggregated version of the original dataset.\n",
        "# This isn’t an optimal use of our compute resources. After the data has been parsed once, we’d like to save the data in its parsed form on the \n",
        "# cluster so that we don’t have to reparse it every time\n",
        "parsed.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtBgCixIBX54",
        "outputId": "e57eacc6-af3b-4e53-c9a2-8a8d916f8d41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id_1: int, id_2: int, cmp_fname_c1: double, cmp_fname_c2: double, cmp_lname_c1: double, cmp_lname_c2: double, cmp_sex: int, cmp_bd: int, cmp_bm: int, cmp_by: int, cmp_plz: int, is_match: boolean]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to know is the relative fraction of records that were matches versus those that were nonmatches\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "parsed.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coBLJjZVBX8Q",
        "outputId": "bc894631-6fcb-439b-cfc8-ede366074e5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+\n",
            "|is_match|  count|\n",
            "+--------+-------+\n",
            "|   false|5728201|\n",
            "|    true|  20931|\n",
            "+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In addition to count, we can also compute more complex aggregations like sums, mins, maxes, means, and \n",
        "# standard deviation using the agg method of the DataFrame API in conjunction with the aggregation functions \n",
        "# defined in the pyspark.sql.functions collection\n",
        "\n",
        "from pyspark.sql.functions import avg, stddev\n",
        "parsed.agg(avg(\"cmp_sex\"), stddev(\"cmp_sex\")).show()"
      ],
      "metadata": {
        "id": "o06mPdRkBX-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42f7858-a545-413c-e232-b683704c6e80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------------------+\n",
            "|     avg(cmp_sex)|stddev_samp(cmp_sex)|\n",
            "+-----------------+--------------------+\n",
            "|0.955001381078048| 0.20730111116897532|\n",
            "+-----------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have the option to treat any DataFrame we create as if it were a database \n",
        "# table and to express our questions using familiar and powerful SQL syntax."
      ],
      "metadata": {
        "id": "fdTGk6VfBYBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to tell the Spark SQL execution engine the name it should associate with the parsed DataFrame\n",
        "\n",
        "parsed.createOrReplaceTempView(\"linkage\")"
      ],
      "metadata": {
        "id": "yhXpapjqBYDi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once our temporary table is registered with the Spark SQL engine, we can query it\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT is_match, COUNT(*) cnt\n",
        "FROM linkage\n",
        "GROUP BY is_match\n",
        "ORDER BY cnt DESC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "UCVCBr20BYF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b671e8-9b4c-47e9-a9c3-dc3687440e82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+\n",
            "|is_match|    cnt|\n",
            "+--------+-------+\n",
            "|   false|5728201|\n",
            "|    true|  20931|\n",
            "+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fast Summary Statistics for DataFrames"
      ],
      "metadata": {
        "id": "MBkYDOuQBYIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the min, max, mean, and standard deviation of all\n",
        "# the non-null values in the numerical columns of a dataframe\n",
        "\n",
        "summary = parsed.describe()\n",
        "summary.show()"
      ],
      "metadata": {
        "id": "6NZQvxC6BYK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73e41c7-347d-48ba-e718-5e7e3e8b1611"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|summary|              id_1|              id_2|      cmp_fname_c1|       cmp_fname_c2|       cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|             cmp_bm|             cmp_by|            cmp_plz|\n",
            "+-------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|  count|           5749132|           5749132|           5748125|             103698|            5749132|               2464|            5749132|            5748337|            5748337|            5748337|            5736289|\n",
            "|   mean| 33324.48559643438| 66587.43558331935|0.7129024704419248| 0.9000176718903281| 0.3156278193069733|0.31841283153174393|  0.955001381078048|0.22446526708507172|0.48885529849763504| 0.2227485966810923|0.00552866147434343|\n",
            "| stddev|23659.859374487736|23620.487613269994|0.3887583596162795|0.27131761057823317|0.33423363396159295| 0.3685670662006656|0.20730111116897532| 0.4172297223846254|0.49987582367791233|0.41609096298317527|0.07414914925419852|\n",
            "|    min|                 1|                 6|               0.0|                0.0|                0.0|                0.0|                  0|                  0|                  0|                  0|                  0|\n",
            "|    max|             99980|            100000|               1.0|                1.0|                1.0|                1.0|                  1|                  1|                  1|                  1|                  1|\n",
            "+-------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use the select method to choose a subset of the columns \n",
        "# to make the summary statistics easier to read and compare:\n",
        "\n",
        "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
      ],
      "metadata": {
        "id": "AeIpnv3nBYNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23486c14-0e28-4a36-ba2f-9f14b3e9fe0e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------------------+\n",
            "|summary|      cmp_fname_c1|       cmp_fname_c2|\n",
            "+-------+------------------+-------------------+\n",
            "|  count|           5748125|             103698|\n",
            "|   mean|0.7129024704419248| 0.9000176718903281|\n",
            "| stddev|0.3887583596162795|0.27131761057823317|\n",
            "|    min|               0.0|                0.0|\n",
            "|    max|               1.0|                1.0|\n",
            "+-------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once we have an overall feel for the distribution of the variables in our data, we\n",
        "# want to understand how the values of those variables are correlated with the value of\n",
        "# the is_match column."
      ],
      "metadata": {
        "id": "dovOjvQJBYP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = parsed.where(\"is_match = true\")\n",
        "match_summary = matches.describe()"
      ],
      "metadata": {
        "id": "BRfWNhbUBYSa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misses = parsed.filter(col(\"is_match\") == False)\n",
        "miss_summary = misses.describe()"
      ],
      "metadata": {
        "id": "IcPWZsyvBYUu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now start to compare our match_summary and miss_summary DataFrames to\n",
        "# see how the distribution of the variables changes depending on whether the record is\n",
        "# a match or a miss. "
      ],
      "metadata": {
        "id": "YAdMU2XBBYXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivoting and Reshaping DataFrames\n",
        "# Transposing i.e. Pivot and Reshaping for better analysis\n"
      ],
      "metadata": {
        "id": "iY_qDuVRBYZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Pandas to do transformation since small dataset\n",
        "# convert summary into a pandas DataFrame:\n",
        "summary_p = summary.toPandas()"
      ],
      "metadata": {
        "id": "1c_bWUZPBYcB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_p.head()\n"
      ],
      "metadata": {
        "id": "3e1MLvgcBYej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "6a4f5d02-c374-4a96-c3dd-21c2bb915d8d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  summary                id_1                id_2        cmp_fname_c1  \\\n",
              "0   count             5749132             5749132             5748125   \n",
              "1    mean   33324.48559643438   66587.43558331935  0.7129024704419248   \n",
              "2  stddev  23659.859374487736  23620.487613269994  0.3887583596162795   \n",
              "3     min                   1                   6                 0.0   \n",
              "4     max               99980              100000                 1.0   \n",
              "\n",
              "          cmp_fname_c2         cmp_lname_c1         cmp_lname_c2  \\\n",
              "0               103698              5749132                 2464   \n",
              "1   0.9000176718903281   0.3156278193069733  0.31841283153174393   \n",
              "2  0.27131761057823317  0.33423363396159295   0.3685670662006656   \n",
              "3                  0.0                  0.0                  0.0   \n",
              "4                  1.0                  1.0                  1.0   \n",
              "\n",
              "               cmp_sex               cmp_bd               cmp_bm  \\\n",
              "0              5749132              5748337              5748337   \n",
              "1    0.955001381078048  0.22446526708507172  0.48885529849763504   \n",
              "2  0.20730111116897532   0.4172297223846254  0.49987582367791233   \n",
              "3                    0                    0                    0   \n",
              "4                    1                    1                    1   \n",
              "\n",
              "                cmp_by              cmp_plz  \n",
              "0              5748337              5736289  \n",
              "1   0.2227485966810923  0.00552866147434343  \n",
              "2  0.41609096298317527  0.07414914925419852  \n",
              "3                    0                    0  \n",
              "4                    1                    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c03b9fde-f886-4aab-bb27-fa74314cef06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>id_1</th>\n",
              "      <th>id_2</th>\n",
              "      <th>cmp_fname_c1</th>\n",
              "      <th>cmp_fname_c2</th>\n",
              "      <th>cmp_lname_c1</th>\n",
              "      <th>cmp_lname_c2</th>\n",
              "      <th>cmp_sex</th>\n",
              "      <th>cmp_bd</th>\n",
              "      <th>cmp_bm</th>\n",
              "      <th>cmp_by</th>\n",
              "      <th>cmp_plz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>count</td>\n",
              "      <td>5749132</td>\n",
              "      <td>5749132</td>\n",
              "      <td>5748125</td>\n",
              "      <td>103698</td>\n",
              "      <td>5749132</td>\n",
              "      <td>2464</td>\n",
              "      <td>5749132</td>\n",
              "      <td>5748337</td>\n",
              "      <td>5748337</td>\n",
              "      <td>5748337</td>\n",
              "      <td>5736289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mean</td>\n",
              "      <td>33324.48559643438</td>\n",
              "      <td>66587.43558331935</td>\n",
              "      <td>0.7129024704419248</td>\n",
              "      <td>0.9000176718903281</td>\n",
              "      <td>0.3156278193069733</td>\n",
              "      <td>0.31841283153174393</td>\n",
              "      <td>0.955001381078048</td>\n",
              "      <td>0.22446526708507172</td>\n",
              "      <td>0.48885529849763504</td>\n",
              "      <td>0.2227485966810923</td>\n",
              "      <td>0.00552866147434343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stddev</td>\n",
              "      <td>23659.859374487736</td>\n",
              "      <td>23620.487613269994</td>\n",
              "      <td>0.3887583596162795</td>\n",
              "      <td>0.27131761057823317</td>\n",
              "      <td>0.33423363396159295</td>\n",
              "      <td>0.3685670662006656</td>\n",
              "      <td>0.20730111116897532</td>\n",
              "      <td>0.4172297223846254</td>\n",
              "      <td>0.49987582367791233</td>\n",
              "      <td>0.41609096298317527</td>\n",
              "      <td>0.07414914925419852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>min</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>max</td>\n",
              "      <td>99980</td>\n",
              "      <td>100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c03b9fde-f886-4aab-bb27-fa74314cef06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c03b9fde-f886-4aab-bb27-fa74314cef06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c03b9fde-f886-4aab-bb27-fa74314cef06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_p.shape"
      ],
      "metadata": {
        "id": "tS5sVp4nBYhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d15c154-8f8b-4cee-c04e-864653ac782d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_p = summary_p.set_index('summary').transpose().reset_index()\n",
        "summary_p = summary_p.rename(columns={'index':'field'})\n",
        "summary_p = summary_p.rename_axis(None, axis=1)\n",
        "summary_p.shape"
      ],
      "metadata": {
        "id": "Nh5RMNlnBYjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c669bcd-c8fc-4c4f-f918-d6d702b74a34"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert it into a Spark DataFrame using SparkSession’s createDataFrame method\n",
        "\n",
        "summaryT = spark.createDataFrame(summary_p)\n",
        "summaryT.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31bCVODg3N6U",
        "outputId": "8f69d5bf-7f0e-4413-b043-0cca54b479a8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-------------------+-------------------+---+------+\n",
            "|       field|  count|               mean|             stddev|min|   max|\n",
            "+------------+-------+-------------------+-------------------+---+------+\n",
            "|        id_1|5749132|  33324.48559643438| 23659.859374487736|  1| 99980|\n",
            "|        id_2|5749132|  66587.43558331935| 23620.487613269994|  6|100000|\n",
            "|cmp_fname_c1|5748125| 0.7129024704419248| 0.3887583596162795|0.0|   1.0|\n",
            "|cmp_fname_c2| 103698| 0.9000176718903281|0.27131761057823317|0.0|   1.0|\n",
            "|cmp_lname_c1|5749132| 0.3156278193069733|0.33423363396159295|0.0|   1.0|\n",
            "|cmp_lname_c2|   2464|0.31841283153174393| 0.3685670662006656|0.0|   1.0|\n",
            "|     cmp_sex|5749132|  0.955001381078048|0.20730111116897532|  0|     1|\n",
            "|      cmp_bd|5748337|0.22446526708507172| 0.4172297223846254|  0|     1|\n",
            "|      cmp_bm|5748337|0.48885529849763504|0.49987582367791233|  0|     1|\n",
            "|      cmp_by|5748337| 0.2227485966810923|0.41609096298317527|  0|     1|\n",
            "|     cmp_plz|5736289|0.00552866147434343|0.07414914925419852|  0|     1|\n",
            "+------------+-------+-------------------+-------------------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the schema of the summaryT DataFrame\n",
        "summaryT.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEUSB4cn3N8u",
        "outputId": "5106f7e8-8f82-46d0-8125-5824a26b637a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- field: string (nullable = true)\n",
            " |-- count: string (nullable = true)\n",
            " |-- mean: string (nullable = true)\n",
            " |-- stddev: string (nullable = true)\n",
            " |-- min: string (nullable = true)\n",
            " |-- max: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we want to analyze the summary statistics as numbers, \n",
        "# we’ll need to convert the values from strings to double\n",
        "\n",
        "from pyspark.sql.types import DoubleType\n",
        "for c in summaryT.columns:\n",
        "    if c == 'field':\n",
        "        continue\n",
        "    summaryT = summaryT.withColumn(c, summaryT[c].cast(DoubleType()))\n",
        "\n",
        "summaryT.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAc5kll13N_P",
        "outputId": "42ab27ce-1a3b-42bb-eeed-dc16ba32d0da"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- field: string (nullable = true)\n",
            " |-- count: double (nullable = true)\n",
            " |-- mean: double (nullable = true)\n",
            " |-- stddev: double (nullable = true)\n",
            " |-- min: double (nullable = true)\n",
            " |-- max: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  let’s implement our logic into a function that we can reuse on \n",
        "# the match_summary and miss_summary DataFrames:\n",
        "\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.types import DoubleType\n",
        "def pivot_summary(desc):\n",
        "    # convert to pandas dataframe\n",
        "    desc_p = desc.toPandas()\n",
        "    # transpose\n",
        "    desc_p = desc_p.set_index('summary').transpose().reset_index()\n",
        "    desc_p = desc_p.rename(columns={'index':'field'})\n",
        "    desc_p = desc_p.rename_axis(None, axis=1)\n",
        "    # convert to Spark dataframe\n",
        "    descT = spark.createDataFrame(desc_p)\n",
        "    # convert metric columns to double from string\n",
        "    for c in descT.columns:\n",
        "        if c == 'field':\n",
        "            continue\n",
        "        else:\n",
        "            descT = descT.withColumn(c, descT[c].cast(DoubleType()))\n",
        "    return descT\n",
        "\n",
        "\n",
        "match_summaryT = pivot_summary(match_summary)\n",
        "miss_summaryT = pivot_summary(miss_summary)"
      ],
      "metadata": {
        "id": "CjZmxvHN3OBn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining DataFrames and Selecting Features\n",
        "# Although the DataFrame API includes a join function, it’s often easier to express \n",
        "# these joins using Spark SQL, especially when the tables we are joining have a \n",
        "# large number of column names in common and we want to be able to clearly \n",
        "# indicate which column we are referring to in our select expressions\n"
      ],
      "metadata": {
        "id": "WK5fh8vX3wf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create temporary views for the match_summaryT and miss_summaryT DataFrames, \n",
        "# join them on the field column, and compute some simple summary \n",
        "# statistics on the resulting rows:\n",
        "\n",
        "match_summaryT.createOrReplaceTempView(\"match_desc\")\n",
        "miss_summaryT.createOrReplaceTempView(\"miss_desc\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT a.field, a.count + b.count total, a.mean - b.mean delta\n",
        "FROM match_desc a INNER JOIN miss_desc b ON a.field = b.field\n",
        "WHERE a.field NOT IN (\"id_1\", \"id_2\")\n",
        "ORDER BY delta DESC, total DESC\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1c46Ci-3wih",
        "outputId": "fa091db6-6926-43d5-e815-ddfc80648b82"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+--------------------+\n",
            "|       field|    total|               delta|\n",
            "+------------+---------+--------------------+\n",
            "|     cmp_plz|5736289.0|  0.9563812499852176|\n",
            "|cmp_lname_c2|   2464.0|  0.8064147192926266|\n",
            "|      cmp_by|5748337.0|  0.7762059675300512|\n",
            "|      cmp_bd|5748337.0|   0.775442311783404|\n",
            "|cmp_lname_c1|5749132.0|   0.683877248260476|\n",
            "|      cmp_bm|5748337.0|  0.5109496938298685|\n",
            "|cmp_fname_c1|5748125.0|  0.2854529057477815|\n",
            "|cmp_fname_c2| 103698.0|  0.0910426806227922|\n",
            "|     cmp_sex|5749132.0|0.032408185250332844|\n",
            "+------------+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANALYSIS\n",
        "# A good feature has two properties: it tends to have significantly different values for\n",
        "# matches and nonmatches (so the difference between the means will be large), and it\n",
        "# occurs often enough in the data that we can rely on it to be regularly available for any\n",
        "# pair of records. By this measure, cmp_fname_c2 isn’t very useful because it’s missing\n",
        "# a lot of the time, and the difference in the mean value for matches and nonmatches\n",
        "# is relatively small—0.09, for a score that ranges from 0 to 1.\n",
        "\n",
        "# The cmp_sex feature also isn’t particularly helpful because even though it’s available \n",
        "# for any pair of records, the difference in means is just 0.03.\n",
        "\n",
        "# Features cmp_plz and cmp_by, on the other hand, are excellent. They almost always\n",
        "# occur for any pair of records, and there is a very large difference in the mean values\n",
        "# (more than 0.77 for both features). Features cmp_bd, cmp_lname_c1, and cmp_bm also\n",
        "# seem beneficial: they are generally available in the dataset, and the difference in mean\n",
        "# values for matches and nonmatches is substantial\n",
        "\n",
        "# Features cmp_fname_c1 and cmp_lname_c2 are more of a mixed bag: cmp_fname_c1\n",
        "# doesn’t discriminate all that well (the difference in the means is only 0.28) even\n",
        "# though it’s usually available for a pair of records, whereas cmp_lname_c2 has a large\n",
        "# difference in the means, but it’s almost always missing. It’s not quite obvious under\n",
        "# what circumstances we should include these features in our model based on this data."
      ],
      "metadata": {
        "id": "6LClyEHx3wlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scoring and Model Evaluation\n",
        "# For our scoring function, we are going to sum up the value of five fields\n",
        "# (cmp_lname_c1, cmp_plz, cmp_by, cmp_bd, and cmp_bm).\n",
        "\n",
        "# Create the required expression string\n",
        "good_features = [\"cmp_lname_c1\", \"cmp_plz\", \"cmp_by\", \"cmp_bd\", \"cmp_bm\"]\n",
        "sum_expression = \" + \".join(good_features)\n",
        "sum_expression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZPnTQI_X3wnN",
        "outputId": "379fcb7d-84e2-498e-81e3-a7296a650a89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cmp_lname_c1 + cmp_plz + cmp_by + cmp_bd + cmp_bm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the sum_expression string for calculating the score. When summing up the values, \n",
        "# we will account for and replace null values with 0 using DataFrame’s fillna method\n",
        "\n",
        "from pyspark.sql.functions import expr\n",
        "scored = parsed.fillna(0, subset=good_features).\\\n",
        "withColumn('score', expr(sum_expression)).\\\n",
        "select('score', 'is_match')\n",
        "scored.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIELtOKb3wpe",
        "outputId": "7ee11655-0e22-4206-b028-efefedbc7565"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|score|is_match|\n",
            "+-----+--------+\n",
            "|  4.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  4.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  4.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The final step in creating our scoring function is to decide what threshold \n",
        "# the score must exceed in order for us to predict that the two records \n",
        "#represent a match. "
      ],
      "metadata": {
        "id": "YOOOE90q3wr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To help us choose a threshold, it’s helpful to create a contingency table (which is\n",
        "# sometimes called a cross tabulation, or crosstab) that counts the number of records\n",
        "# whose scores fall above/below the threshold value crossed with the number of records\n",
        "# in each of those categories that were/were not matches\n",
        "\n",
        "def crossTabs(scored: DataFrame, t: DoubleType) -> DataFrame:\n",
        "    return scored.selectExpr(f\"score >= {t} as above\", \"is_match\").\\\n",
        "        groupBy(\"above\").pivot(\"is_match\", (\"true\", \"false\")).\\\n",
        "        count()"
      ],
      "metadata": {
        "id": "p7xFf7S83wue"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossTabs(scored, 2.0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKtrCOSQ3wxD",
        "outputId": "9d49fefc-1a89-4df8-dfea-2c3a409a8499"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+\n",
            "|above| true|  false|\n",
            "+-----+-----+-------+\n",
            "| true|20931| 596414|\n",
            "|false| null|5131787|\n",
            "+-----+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crossTabs(scored, 3.0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Koun2bW-3wz3",
        "outputId": "1e65e88a-9a2d-407f-e4ae-599060545613"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+\n",
            "|above| true|  false|\n",
            "+-----+-----+-------+\n",
            "| true|20916| 315213|\n",
            "|false|   15|5412988|\n",
            "+-----+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crossTabs(scored, 4.0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u3_pYCv3w2S",
        "outputId": "f683c17d-dc77-4dbc-d4b5-edfdc1be012e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+\n",
            "|above| true|  false|\n",
            "+-----+-----+-------+\n",
            "| true|20871|    637|\n",
            "|false|   60|5727564|\n",
            "+-----+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crossTabs(scored, 5.0).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTSOq1013w5K",
        "outputId": "22405a3b-e137-41a4-c2d8-402b0788c7f1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------+\n",
            "|above| true|  false|\n",
            "+-----+-----+-------+\n",
            "| true|19697|      5|\n",
            "|false| 1234|5728196|\n",
            "+-----+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By applying a high threshold value of 4.0, meaning that the average of the five\n",
        "# features is 0.8, we can filter out almost all of the nonmatches while keeping \n",
        "# over 90% of the matches\n"
      ],
      "metadata": {
        "id": "ykbW33p83w7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OFMy5VJ3w-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3ydv9jN3xA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_0CKzbW3xDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2gwWkZI3xGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2LY4dVX93xIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQZM9Tkv3xK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7YmKkHVx3xNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y6JoPfIs3xQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9zxaPPSYBYl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}