{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGtG3i0rhvOj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dga9ltPhvQ_",
        "outputId": "df1dca15-5b9d-4cd0-b92c-31fc385e766e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=806d288a9cff00792d752c04195f34b7dd365a0cf9fc22f1e495bae8e037489c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCe1RN-fhvTQ"
      },
      "outputs": [],
      "source": [
        "#GDRIVE\n",
        "filepath = \"/content/drive/MyDrive/adv_analytics/profiledata_06-May-2005/user_artist_data.txt\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1Huf4lyhvVu"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Adv_Analytics').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXbWfXgJhvYM"
      },
      "outputs": [],
      "source": [
        "#The main dataset is in the user_artist_data.txt file. It contains about \n",
        "# 141,000 unique users, and 1.6 million unique artists. About 24.2 million \n",
        "# users’ plays of artists are recorded, along with their counts.\n",
        "\n",
        "raw_user_artist_data = spark.read.text(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn8ZhDQrhvaf",
        "outputId": "804ef612-af96-4170-fcb2-9ff3dbf0e18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|              value|\n",
            "+-------------------+\n",
            "|       1000002 1 55|\n",
            "| 1000002 1000006 33|\n",
            "|  1000002 1000007 8|\n",
            "|1000002 1000009 144|\n",
            "|1000002 1000010 314|\n",
            "+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "raw_user_artist_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QntZEVwqhvcz",
        "outputId": "e6c34d2a-bda2-4da3-fab6-1cec1c7ac54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|1134999\\t06Crazy ...|\n",
            "|6821360\\tPang Nak...|\n",
            "|10113088\\tTerfel,...|\n",
            "|10151459\\tThe Fla...|\n",
            "|6826647\\tBodensta...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The dataset also gives the names of each artist by ID in the artist_data.txt file\n",
        "#This might have misspellings etc\n",
        "raw_artist_data = spark.read.text(\"/content/drive/MyDrive/adv_analytics/profiledata_06-May-2005/artist_data.txt\")\n",
        "raw_artist_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLEWqfc3hvfR",
        "outputId": "b7cd0949-f280-4652-c0ff-4d652041fab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|            value|\n",
            "+-----------------+\n",
            "| 1092764\\t1000311|\n",
            "| 1095122\\t1000557|\n",
            "| 6708070\\t1007267|\n",
            "|10088054\\t1042317|\n",
            "| 1195917\\t1042317|\n",
            "+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#artists mapped to proper names without error\n",
        "raw_artist_alias = spark.read.text(\"/content/drive/MyDrive/adv_analytics/profiledata_06-May-2005/artist_alias.txt\")\n",
        "raw_artist_alias.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9jCUu7khvhp",
        "outputId": "d839482a-7846-4a23-a848-8afd51cccd00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|              value|\n",
            "+-------------------+\n",
            "|       1000002 1 55|\n",
            "| 1000002 1000006 33|\n",
            "|  1000002 1000007 8|\n",
            "|1000002 1000009 144|\n",
            "|1000002 1000010 314|\n",
            "|  1000002 1000013 8|\n",
            "| 1000002 1000014 42|\n",
            "| 1000002 1000017 69|\n",
            "|1000002 1000024 329|\n",
            "|  1000002 1000025 1|\n",
            "+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preparing the Data\n",
        "raw_user_artist_data.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFxpKvr83S9P"
      },
      "outputs": [],
      "source": [
        "# Each line of the file contains a user ID, an artist ID, \n",
        "# and a play count, separated by spaces.\n",
        "\n",
        "# We split this 3 things for easy statistics calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq1yDcJS3TEI"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import split, min, max\n",
        "from pyspark.sql.types import IntegerType, StringType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjSBY9_B3TGw"
      },
      "outputs": [],
      "source": [
        "user_artist_df = raw_user_artist_data.withColumn('user',\n",
        "split(raw_user_artist_data['value'], ' ').\\\n",
        "getItem(0).\\\n",
        "cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxb3ggK63TLM"
      },
      "outputs": [],
      "source": [
        "user_artist_df = user_artist_df.withColumn('artist',\n",
        "split(raw_user_artist_data['value'], ' ').\\\n",
        "getItem(1).\\\n",
        "cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTsetsAa3TOK"
      },
      "outputs": [],
      "source": [
        "user_artist_df = user_artist_df.withColumn('count',\n",
        "split(raw_user_artist_data['value'], ' ').\\\n",
        "getItem(2).\\\n",
        "cast(IntegerType())).drop('value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvkbWCG73TQv",
        "outputId": "425fe72e-d106-40b5-f517-8f4abcf22ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---------+-----------+-----------+\n",
            "|min(user)|max(user)|min(artist)|max(artist)|\n",
            "+---------+---------+-----------+-----------+\n",
            "|       90|  2443548|          1|   10794401|\n",
            "+---------+---------+-----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_artist_df.select([min(\"user\"), max(\"user\"), min(\"artist\"),\\\n",
        "max(\"artist\")]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAZ8vFtj3TTl",
        "outputId": "96d968b7-1aeb-4df5-a576-2b9e01da8012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+\n",
            "|      id|                name|\n",
            "+--------+--------------------+\n",
            "| 1134999|        06Crazy Life|\n",
            "| 6821360|        Pang Nakarin|\n",
            "|10113088|Terfel, Bartoli- ...|\n",
            "|10151459| The Flaming Sidebur|\n",
            "| 6826647|   Bodenstandig 3000|\n",
            "+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# To know the artist names corresponding to the numeric IDs. raw_artist_data \n",
        "# contains the artist ID and name separated by a tab. \n",
        "# PySpark’s split function accepts regular expression values for the pattern\n",
        "# parameter. We can split using the whitespace character \\s\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "artist_by_id = raw_artist_data.withColumn('id', split(col('value'), '\\s+', 2).\\\n",
        "getItem(0).\\\n",
        "cast(IntegerType()))\n",
        "\n",
        "artist_by_id = artist_by_id.withColumn('name', split(col('value'), '\\s+', 2).\\\n",
        "getItem(1).\\\n",
        "cast(StringType())).drop('value')\n",
        "\n",
        "artist_by_id.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLO1Z3Od3TWK",
        "outputId": "05657187-91b7-4205-c6ad-5de5a3cd1516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-------+\n",
            "|  artist|  alias|\n",
            "+--------+-------+\n",
            "| 1092764|1000311|\n",
            "| 1095122|1000557|\n",
            "| 6708070|1007267|\n",
            "|10088054|1042317|\n",
            "| 1195917|1042317|\n",
            "+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Parse the alias dataset too\n",
        "\n",
        "artist_alias = raw_artist_alias.withColumn('artist',\n",
        "                                           split(col('value'), '\\s+').\\\n",
        "                                           getItem(0).\\\n",
        "                                           cast(IntegerType())).\\\n",
        "                                withColumn('alias',\n",
        "                                           split(col('value'), '\\s+').\\\n",
        "                                           getItem(1).\\\n",
        "                                           cast(StringType())).\\\n",
        "                                           drop('value')\n",
        "                                           \n",
        "artist_alias.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNm9WiM33TZH",
        "outputId": "dd9b91d3-226b-4088-9ecb-c74ca2c4b8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------+\n",
            "|     id|          name|\n",
            "+-------+--------------+\n",
            "|1000311| Steve Winwood|\n",
            "|1092764|Winwood, Steve|\n",
            "+-------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# This will prove the alias entry is correct\n",
        "artist_by_id.filter(artist_by_id.id.isin(1092764, 1000311)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Z8Skrq3Tba"
      },
      "outputs": [],
      "source": [
        "# One Transformation\n",
        "# The aliases dataset should be applied to convert all artist IDs \n",
        "#to a canonical ID, if a different canonical ID exists\n",
        "\n",
        "from pyspark.sql.functions import broadcast, when\n",
        "\n",
        "train_data = train_data = user_artist_df.join(broadcast(artist_alias),\n",
        "'artist', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj9s2F1r3TeM"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.withColumn('artist',\n",
        "when(col('alias').isNull(), col('artist')).\\\n",
        "otherwise(col('alias')))\n",
        "\n",
        "train_data = train_data.withColumn('artist', col('artist').\\\n",
        "cast(IntegerType())).\\\n",
        "drop('alias')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF4T0R_i_OsQ",
        "outputId": "66b25e93-06b9-43e2-e02a-0550a096c6aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[artist: int, user: int, count: int]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehoZejAK_P4k",
        "outputId": "0bbdcedd-5641-4cc2-a831-b29e1d4cd4a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24296858"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROq1tzHV_cov"
      },
      "outputs": [],
      "source": [
        "# We broadcast the artist_alias DataFrame created earlier. \n",
        "# This makes Spark send and hold in memory just one copy \n",
        "# for each executor in the cluster\n",
        "\n",
        "# As a rule of thumb, it’s helpful to broadcast a significantly \n",
        "#smaller dataset when performing a join with a very big dataset\n",
        "\n",
        "#The call to cache suggests to Spark that this DataFrame should be \n",
        "# temporarily stored after being computed and, furthermore, kept in \n",
        "# memory in the cluster. This is helpful because the ALS algorithm is \n",
        "# iterative and will typically need to access this data 10 times or more.\n",
        "\n",
        "# When you use cache or persist, the DataFrame is not fully cached \n",
        "# until you trigger an action that goes through every record (e.g., count)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMBULIt73TgV"
      },
      "outputs": [],
      "source": [
        "# Building a First Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkFOymwchvkS"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "model = ALS(rank=10, seed=0, maxIter=5, regParam=0.1,\n",
        "implicitPrefs=True, alpha=1.0, userCol='user',\n",
        "itemCol='artist', ratingCol='count'). \\\n",
        "fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_xAJ33HhvnB"
      },
      "outputs": [],
      "source": [
        "# see some feature vectors, try the following, which displays just one row\n",
        "# and does not truncate the wide display of the feature vector:\n",
        "model.userFactors.show(1, truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DF7COzshvon"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjfybsG0CwKn"
      },
      "outputs": [],
      "source": [
        "# Spot Checking Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp4AzjrRCwNc"
      },
      "outputs": [],
      "source": [
        "# Take, for example, user 2093760. First, let’s look at his or her plays \n",
        "# to get a sense of the person’s tastes. Extract the IDs of artists that \n",
        "# this user has listened to and print their names.\n",
        "\n",
        "user_id = 2093760\n",
        "\n",
        "#Collect dataset of artist ID.\n",
        "existing_artist_ids = train_data.filter(train_data.user == user_id) \\\n",
        ".select(\"artist\").collect()\n",
        "existing_artist_ids = [i[0] for i in existing_artist_ids]\n",
        "\n",
        "#Filter in those artists.\n",
        "artist_by_id.filter(col('id').isin(existing_artist_ids)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UcFRQRKCwQD"
      },
      "outputs": [],
      "source": [
        "# Now make recommendations\n",
        "\n",
        "user_subset = train_data.select('user').where(col('user') == user_id).distinct()\n",
        "top_predictions = model.recommendForUserSubset(user_subset, 5)\n",
        "top_predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mM7pV6mCwSu"
      },
      "outputs": [],
      "source": [
        "# The resulting recommendations contain lists comprised of artist ID and,\n",
        "# of course, “predictions.” For this type of ALS algorithm, the prediction\n",
        "# is an opaque value normally between 0 and 1, where higher values mean a\n",
        "# better recommendation. It is not a probability but can be thought of as\n",
        "# an estimate of a 0/1 value indicating whether the user won’t or will \n",
        "# interact with the artist, respectively.\n",
        "\n",
        "top_predictions_pandas = top_predictions.toPandas()\n",
        "print(top_prediction_pandas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DW7OtFGDgOJ"
      },
      "outputs": [],
      "source": [
        "recommended_artist_ids = [i[0] for i in top_predictions_pandas.\\\n",
        "recommendations[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpkXw389DgQ2"
      },
      "outputs": [],
      "source": [
        "artist_by_id.filter(col('id').isin(recommended_artist_ids)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJojKh6kDgTd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meTkb2_jDgWB"
      },
      "outputs": [],
      "source": [
        "# Evaluating Recommendation Quality\n",
        "# Train Test Split "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zipbYdGDgYm"
      },
      "outputs": [],
      "source": [
        "# area under the curve AUC may be viewed as the probability that a \n",
        "# randomly chosen good recommendation ranks above a randomly chosen\n",
        "# bad recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eorkwrRMDgbM"
      },
      "outputs": [],
      "source": [
        "# Computing AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Yd6ZHkDgdi"
      },
      "outputs": [],
      "source": [
        "def area_under_curve(positive_data,b_all_artist_IDs,predict_function):\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMECO0WwDggD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdP7csniDgiv"
      },
      "outputs": [],
      "source": [
        "all_data = user_artist_df.join(broadcast(artist_alias), 'artist', how='left') \\\n",
        ".withColumn('artist', when(col('alias').isNull(), col('artist'))\\\n",
        ".otherwise(col('alias'))) \\\n",
        ".withColumn('artist', col('artist').cast(IntegerType())).drop('alias')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBWAEPneDglL"
      },
      "outputs": [],
      "source": [
        "train_data, cv_data = all_data.randomSplit([0.9, 0.1], seed=54321)\n",
        "train_data.cache()\n",
        "cv_data.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX2awY4kDgns"
      },
      "outputs": [],
      "source": [
        "all_artist_ids = all_data.select(\"artist\").distinct().count()\n",
        "b_all_artist_ids = broadcast(all_artist_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4ek4KywDgqP"
      },
      "outputs": [],
      "source": [
        "model = ALS(rank=10, seed=0, maxIter=5, regParam=0.1,\n",
        "implicitPrefs=True, alpha=1.0, userCol='user',\n",
        "itemCol='artist', ratingCol='count') \\\n",
        ".fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdCUDIbkCwVo"
      },
      "outputs": [],
      "source": [
        "area_under_curve(cv_data, b_all_artist_ids, model.transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-BgEd9FCwX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A3CRQl6IZkn"
      },
      "outputs": [],
      "source": [
        "some_users = all_data.select(\"user\").distinct().limit(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-dAwayzIZnk"
      },
      "outputs": [],
      "source": [
        "val someRecommendations = someUsers.map(userID => (userID, makeRecommendations(model, userID, 5)))\n",
        "someRecommendations.foreach { case (userID, recsDF) =>\n",
        "val recommendedArtists = recsDF.select(\"artist\").as[Int].collect()\n",
        "println(s\"$userID -> ${recommendedArtists.mkString(\", \")}\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dANwYDlIZqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpqsaI7tIZuF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
